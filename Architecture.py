# -*- coding: utf-8 -*-
"""ASSIGNEMENT3_DIVY.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hnOA2FMEnWNCO874DrwJXZMQsFVlJtfz
"""
import sys

import numpy as np
import scipy as sp
import pandas as pd
data = pd.read_csv(sys.argv[1],header=None,delimiter=' ').values

X_train=data[:,:-2]
y1=data[:,-1]
y2=data[:,-2]
X_train = X_train.reshape(len(X_train),3,32,32).transpose([0,2, 3, 1])/255

from keras.utils import to_categorical
y_train = to_categorical(y1)

from keras.models import Model
from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \
    BatchNormalization, concatenate, AveragePooling2D
from keras.optimizers import Adam
import matplotlib.pyplot as plt

from keras.models import Sequential

from keras.layers import Conv2D,Activation,Dense,MaxPooling2D,Flatten,BatchNormalization,Dropout,GlobalAveragePooling2D

model = Sequential()

model.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3),padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.30))
model.add(BatchNormalization())

model.add(Conv2D(128,(3,3),activation='relu',padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.30))
model.add(BatchNormalization())

model.add(Conv2D(256,(3,3),activation='relu',padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.30))
model.add(BatchNormalization())

model.add(GlobalAveragePooling2D())

model.add(Dense(512,use_bias=True,activation='relu'))
model.add(Dropout(0.50))
model.add(BatchNormalization())

model.add(Dense(256,use_bias=True,activation='relu'))
model.add(Dropout(0.50))
model.add(BatchNormalization())

model.add(Dense(100,activation='softmax'))
from keras.callbacks import EarlyStopping
es=EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


history = model.fit(X_train, y_train, validation_split=0.10, epochs = 150 ,batch_size=1000,callbacks=[es])

data1 = pd.read_csv(sys.argv[2],header=None,delimiter=' ').values
X_test=data1[:,:-2]
X_test = X_test.reshape(len(X_test),3,32,32).transpose([0,2, 3, 1])/255
y_test=model.predict(X_test)
y_test=y_test.argmax(axis=1)

np.savetxt(sys.argv[3],y_test,delimiter='\n')
